{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "SEED = 2022\n",
    "np.random.seed(SEED)\n",
    "\n",
    "final_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = torch.load('data/Training/X_train_diet.pt') # torch.Size([16008, 240, 320, 1])\n",
    "X_test_ = torch.load('data/Testing/X_test_diet.pt') # torch.Size([1596, 240, 320, 1])\n",
    "\n",
    "Y_train_ = pd.read_csv('data/Training/Y_train.csv')\n",
    "Y_test_ = pd.read_csv('data/Testing/Y_test.csv')\n",
    "\n",
    "# dataframe to tensor\n",
    "Y_train_ = torch.tensor(Y_train_.values)  # torch.Size([16008, 63])\n",
    "Y_test_ = torch.tensor(Y_test_.values)  # torch.Size([1596, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten image\n",
    "\n",
    "B, H, W, C = X_train_.shape\n",
    "X_train_ = X_train_.reshape(B, -1)  # torch.Size([16008, 76800])\n",
    "\n",
    "B, H, W, C = X_test_.shape\n",
    "X_test_ = X_test_.reshape(B, -1)  # torch.Size([1596, 76800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_split_dataset(X_train_, X_test_, Y_train_, Y_test_, sample_size, valid_size):\n",
    "\n",
    "    # sample train set\n",
    "    n_train = len(X_train_)\n",
    "    indices = list(range(n_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(sample_size * n_train))\n",
    "    sample_indices = indices[:split]\n",
    "    X_train_ = X_train_[sample_indices]\n",
    "    Y_train_ = Y_train_[sample_indices]\n",
    "\n",
    "    # # sample test set\n",
    "    # n_test = len(X_test_)\n",
    "    # indices = list(range(n_test))\n",
    "    # np.random.shuffle(indices)\n",
    "    # split = int(np.floor(sample_size * n_test))\n",
    "    # sample_indices = indices[:split]\n",
    "    # X_test_ = X_test_[sample_indices]\n",
    "    # Y_test_ = Y_test_[sample_indices]\n",
    "\n",
    "    # split train, valid set\n",
    "    n_train = len(X_train_)                  \n",
    "    indices = list(range(n_train))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split = int(np.floor(valid_size * n_train)) \n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_set = TensorDataset(X_train_, Y_train_)\n",
    "    train_sampler, valid_sampler = SubsetRandomSampler(train_idx), SubsetRandomSampler(valid_idx) \n",
    "    train_loader = DataLoader(train_set, batch_size=len(train_sampler), sampler=train_sampler)\n",
    "    valid_loader = DataLoader(train_set, batch_size=len(valid_sampler), sampler=valid_sampler)\n",
    "\n",
    "    # save final data\n",
    "    for img, labels in train_loader:\n",
    "        X_train = img\n",
    "        Y_train = labels\n",
    "    for img, labels in valid_loader:\n",
    "        X_valid = img\n",
    "        Y_valid = labels\n",
    "    X_test = X_test_\n",
    "    Y_test = Y_test_\n",
    "\n",
    "    # print shape\n",
    "    print('\\n Sample size: ', sample_size)\n",
    "    print('X_train: ', X_train.shape)\n",
    "    print('X_valid: ', X_valid.shape)\n",
    "    print('X_test: ', X_test.shape)\n",
    "    print('Y_train: ', Y_train.shape)\n",
    "    print('Y_valid: ', Y_valid.shape)\n",
    "    print('Y_test: ', Y_test.shape)\n",
    "\n",
    "    return X_train, X_valid, X_test, Y_train, Y_valid, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_runtime_dict = {}  \n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [2, 5], # The number of trees in the forest, default=100\n",
    "#     'min_samples_split': [2] # default=2\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150], # The number of trees in the forest, default=100\n",
    "    'min_samples_split': [2, 5, 10], # default=2\n",
    "    'max_depth': [None, 2, 5], # default=None\n",
    "    'max_features': ['sqrt', 'log2', None] # The number of features to consider when looking for the best split, default=None(max_features=n_features)\n",
    "}\n",
    "\n",
    "grid_list = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sample size:  0.3\n",
      "X_train:  torch.Size([3842, 76800])\n",
      "X_valid:  torch.Size([960, 76800])\n",
      "X_test:  torch.Size([1596, 76800])\n",
      "Y_train:  torch.Size([3842, 63])\n",
      "Y_valid:  torch.Size([960, 63])\n",
      "Y_test:  torch.Size([1596, 63])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sample_size_list = [0.3, 0.6, 1.0]\n",
    "\n",
    "for sample_size in tqdm(sample_size_list):\n",
    "\n",
    "    X_train, X_valid, X_test, Y_train, Y_valid, Y_test = sample_and_split_dataset(\n",
    "        X_train_, X_test_, Y_train_, Y_test_, sample_size=sample_size, valid_size=0.2)\n",
    "\n",
    "    for case in tqdm(grid_list):\n",
    "\n",
    "        regr = RandomForestRegressor(\n",
    "            n_estimators=case['n_estimators'], min_samples_split=case['min_samples_split'],\n",
    "            max_depth=case['max_depth'], max_features=case['max_features'],\n",
    "            random_state=SEED)\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        regr.fit(X_train, Y_train)\n",
    "        train_time = datetime.now() - start_time\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        pred = regr.predict(X_valid)\n",
    "        valid_time = datetime.now() - start_time\n",
    "        valid_error = mean_squared_error(Y_valid, pred)\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        pred = regr.predict(X_test)\n",
    "        test_time = datetime.now() - start_time\n",
    "        test_error = mean_squared_error(Y_test, pred)\n",
    "\n",
    "        acc_runtime_dict[str(case)] = dict({'train_time': train_time,\n",
    "                                            'valid_time': valid_time, 'valid_error': valid_error,\n",
    "                                            'test_time': test_time, 'test_error': test_error})\n",
    "\n",
    "    final_dict[sample_size] = acc_runtime_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 결과 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('result_RF.pickle', 'wb') as f:\n",
    "    pickle.dump(final_dict, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('result_RF.pickle', 'rb') as f:\n",
    "    result_RF = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('AML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b32c03290ac83e85360a6b25c84a4d7d0173ff69cc4741b1b57cc3b22dc3e49c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
