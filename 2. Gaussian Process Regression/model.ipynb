{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\")\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  torch.Size([800, 21]) torch.Size([800, 7])\n",
      "valid set:  torch.Size([200, 21]) torch.Size([200, 7])\n",
      "test set:  torch.Size([100, 21]) torch.Size([100, 7])\n"
     ]
    }
   ],
   "source": [
    "'split data'\n",
    "'first 21 columns are input variables and last 7 columns are output variables'\n",
    "\n",
    "train_data = pd.read_csv('./data/SARCOSTst.csv', header=None)[:1000]\n",
    "test_data = pd.read_csv('./data/SARCOSTrn.csv', header=None)[:100]\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_data.iloc[:,:21], train_data.iloc[:,-7:], test_size=0.2)\n",
    "X_test, Y_test = test_data.iloc[:,:21], test_data.iloc[:,-7:]\n",
    "\n",
    "X_train = torch.tensor(X_train.values).to(device)\n",
    "X_valid = torch.tensor(X_valid.values).to(device)\n",
    "Y_train = torch.tensor(Y_train.values).to(device)\n",
    "Y_valid = torch.tensor(Y_valid.values).to(device)\n",
    "X_test = torch.tensor(X_test.values).to(device)\n",
    "Y_test = torch.tensor(Y_test.values).to(device)\n",
    "\n",
    "print('train set: ', X_train.shape, Y_train.shape)\n",
    "print('valid set: ', X_valid.shape, Y_valid.shape)\n",
    "print('test set: ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearKernel:\n",
    "    \"\"\"\n",
    "    standard dot product kernel k(a,b) = a^\\top b\n",
    "    :input: X1 (N*D), X2 (M*D)\n",
    "    :output: covariance matrix (N*M)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, X1, X2):\n",
    "        # return torch.tensor([[torch.dot(x1, x2) for x1 in X1] for x2 in X2]) \n",
    "        return X1 @ X2.T \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianKernel:\n",
    "    \"\"\"\n",
    "    isotropic Gaussian kernel\n",
    "    :input: X1 (N*D), X2 (M*D)\n",
    "    :output: covariance matrix (N*M)\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_k=1):\n",
    "        self.sigma_k = sigma_k # isotropic Gaussian kernel variance (Hyperparameter !)\n",
    "\n",
    "    def __call__(self, X1, X2):\n",
    "        # return np.exp(-(np.sum(X1**2, axis=1).values.reshape(-1, 1) +\n",
    "        #                 np.sum(X2**2, axis=1).values.reshape(1, -1) - 2*X1@X2.T) / pow(self.sigma_k, 2))\n",
    "        return torch.exp(-(torch.sum(X1**2, axis=1).reshape(-1, 1) +\n",
    "                           torch.sum(X2**2, axis=1).reshape(1, -1) - 2*X1@X2.T) / pow(self.sigma_k, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquaredExponentialKernel:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GP regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP_Regression(nn.Module):\n",
    "    def __init__(self, K, sigma_n, device):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.sigma_n = nn.Parameter(torch.tensor(sigma_n), requires_grad=True)  # noise variance (Hyperparameter)\n",
    "        self.device = device\n",
    "        self.Sigma = torch.diag(torch.ones(7)) * self.sigma_n # output dim (=7)\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_test):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.N = X_train.shape[0]\n",
    "        self.M = X_test.shape[0]\n",
    "        self.D = Y_train.shape[1] # output dim (=7)\n",
    "        self.I = torch.eye(self.N)\n",
    "        # sufficient statistics\n",
    "        self.K_X_X = self.K(self.X_train, self.X_train)\n",
    "        self.K_X_X = torch.block_diag(*[self.K_X_X]*self.D) # coregionalisation matrix (C) is an identity matrix with DxD\n",
    "        self.K_Xt_X = self.K(self.X_test, self.X_train)\n",
    "        self.K_Xt_X = torch.block_diag(*[self.K_Xt_X]*self.D)\n",
    "        self.K_X_Xt = self.K_Xt_X.T\n",
    "        self.K_Xt_Xt = self.K(self.X_test, self.X_test)\n",
    "        self.K_Xt_Xt = torch.block_diag(*[self.K_Xt_Xt]*self.D)\n",
    "        self.vec_Y = self.Y_train.T.reshape(self.D*self.N) # Y concat\n",
    "\n",
    "    def predict(self):\n",
    "        # calculate predictive mean\n",
    "        mean = self.K_Xt_X @ torch.linalg.inv( self.K_X_X + torch.kron(self.Sigma, self.I).to(self.device) ) @ self.vec_Y\n",
    "        return mean.reshape(self.D, -1).T # to compare with Y_test\n",
    "\n",
    "    def __NLL_term_1__(self):\n",
    "        return -0.5*(self.M*self.D) * torch.log(torch.tensor([2*torch.pi]))\n",
    "\n",
    "    def __NLL_term_2__(self, CR): # Omega <- I\n",
    "        Sigma = torch.diag(torch.ones(self.D)) * self.sigma_n\n",
    "        SI = torch.kron(Sigma, self.I).to(self.device) \n",
    "        K = CR + SI\n",
    "        return -0.5 * torch.log(torch.det(K))\n",
    "\n",
    "    def __NLL_term_3__(self, CR): # Omega <- I\n",
    "        Sigma = torch.diag(torch.ones(self.D)) * self.sigma_n\n",
    "        SI = torch.kron(Sigma, self.I).to(self.device)\n",
    "        K = CR + SI\n",
    "        vec_Y = self.Y_train.T.reshape(self.D*self.N)  # Y concat\n",
    "        return -0.5 * vec_Y.T @ torch.linalg.inv(K) @ vec_Y\n",
    "    \n",
    "    def calculate_NLL(self):\n",
    "        K_X_X = self.K(self.X_train, self.X_train)\n",
    "        CR = torch.block_diag(*[K_X_X]*self.D) \n",
    "        return self.__NLL_term_1__().to(self.device) + self.__NLL_term_2__(CR).to(self.device) + self.__NLL_term_3__(CR).to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Parameter: 0.05000000074505806\n",
      "\n",
      "[Iteration 0]\n",
      "NLL: -970830.0\n",
      "Paremeter:  -18.234878540039062\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 1]\n",
      "NLL: -inf\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 2]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 3]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 4]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\YOUNGBIN\\Documents\\Jupyter Lab\\Advanced-Machine-Learning\\2. Gaussian Process Regression\\model.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=10'>11</a>\u001b[0m nll \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcalculate_NLL()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=12'>13</a>\u001b[0m nll\u001b[39m.\u001b[39;49mbackward() \u001b[39m# calculate derivatives\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m# update parameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNLL: \u001b[39m\u001b[39m{\u001b[39;00mnll\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AML\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AML\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m--> <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GP_Regression(K=GaussianKernel(), sigma_n=0.05, device=device)\n",
    "model.fit(X_train, Y_train, X_test)\n",
    "# model.predict() # 이거 한번 거쳐야 self.vec_Y 사용 가능\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00002)\n",
    "n_iter=50\n",
    "print(f'Initial Parameter: {list(model.parameters())[0].item()}')\n",
    "print('')\n",
    "for i in range(n_iter):\n",
    "    print(f'[Iteration {i}]')\n",
    "    nll = model.calculate_NLL()\n",
    "    optimizer.zero_grad()\n",
    "    nll.backward() # calculate derivatives\n",
    "    optimizer.step() # update parameters\n",
    "    print(f\"NLL: {nll.item()}\")\n",
    "    for i in range(len(list(model.parameters()))):\n",
    "        print('Paremeter: ', list(model.parameters())[i].item())\n",
    "    pred = model.predict()\n",
    "    mse = nn.MSELoss()(pred, Y_test).item()\n",
    "    print(f\"MSE:\", mse)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f37873089bc99999a4c22445a6971dc9322bb05dc63dba22dd50e8a2bf7bc1c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('AML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
