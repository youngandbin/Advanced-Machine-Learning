{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "random_seed=2022\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CV\n",
    "from sklearn.model_selection import ParameterGrid # creates a parameter grid to search for\n",
    "from sklearn.model_selection import KFold # splits data into k-fold train and valid set\n",
    "\n",
    "# done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data\n",
    "- 'first 21 columns are input variables and last 7 columns are output variables'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  torch.Size([31587, 21]) torch.Size([31587, 7])\n",
      "valid set:  torch.Size([7897, 21]) torch.Size([7897, 7])\n",
      "test set:  torch.Size([5000, 21]) torch.Size([5000, 7])\n"
     ]
    }
   ],
   "source": [
    "# train_data = pd.read_csv('./data/SARCOSTst.csv', header=None)\n",
    "# test_data = pd.read_csv('./data/SARCOSTrn.csv', header=None)\n",
    "\n",
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(train_data.iloc[:,:21], train_data.iloc[:,-7:], test_size=0.2)\n",
    "# X_test, Y_test = test_data.iloc[:, :21], test_data.iloc[:, -7:]\n",
    "\n",
    "# X_train = torch.tensor(X_train.values).to(device)\n",
    "# Y_train = torch.tensor(Y_train.values).to(device)\n",
    "# X_valid = torch.tensor(X_valid.values).to(device)\n",
    "# Y_valid = torch.tensor(Y_valid.values).to(device)\n",
    "# X_test = torch.tensor(X_test.values).to(device)\n",
    "# Y_test = torch.tensor(Y_test.values).to(device)\n",
    "\n",
    "# print('train set: ', X_train.shape, Y_train.shape)\n",
    "# print('valid set: ', X_valid.shape, Y_valid.shape)\n",
    "# print('test set: ', X_test.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  torch.Size([39484, 21]) torch.Size([39484, 7])\n",
      "test set:  torch.Size([5000, 21]) torch.Size([5000, 7])\n"
     ]
    }
   ],
   "source": [
    "# in case of using cross-validation\n",
    "\n",
    "train_data = pd.read_csv('./data/SARCOSTst.csv', header=None)\n",
    "test_data = pd.read_csv('./data/SARCOSTrn.csv', header=None)\n",
    "\n",
    "X_train, Y_train = train_data.iloc[:,:21], train_data.iloc[:,-7:]\n",
    "X_test, Y_test = test_data.iloc[:,:21], test_data.iloc[:,-7:]\n",
    "\n",
    "X_train = torch.tensor(X_train.values).to(device)\n",
    "Y_train = torch.tensor(Y_train.values).to(device)\n",
    "X_test = torch.tensor(X_test.values).to(device)\n",
    "Y_test = torch.tensor(Y_test.values).to(device)\n",
    "\n",
    "print('train set: ', X_train.shape, Y_train.shape)\n",
    "print('test set: ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearKernel:\n",
    "    \"\"\"\n",
    "    standard dot product kernel k(a,b) = a^\\top b\n",
    "    :input: X1 (N*D), X2 (M*D)\n",
    "    :output: covariance matrix (N*M)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, X1, X2):\n",
    "        # return torch.tensor([[torch.dot(x1, x2) for x1 in X1] for x2 in X2]) \n",
    "        return X1 @ X2.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianKernel:\n",
    "    \"\"\"\n",
    "    isotropic Gaussian kernel\n",
    "    :input: X1 (N*D), X2 (M*D)\n",
    "    :output: covariance matrix (N*M)\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma_k):\n",
    "        self.sigma_k = sigma_k # isotropic Gaussian kernel variance \n",
    "\n",
    "    def __call__(self, X1, X2):\n",
    "        # return np.exp(-(np.sum(X1**2, axis=1).values.reshape(-1, 1) +\n",
    "        #                 np.sum(X2**2, axis=1).values.reshape(1, -1) - 2*X1@X2.T) / pow(self.sigma_k, 2))\n",
    "        return torch.exp(-(torch.sum(X1**2, axis=1).reshape(-1, 1) +\n",
    "                           torch.sum(X2**2, axis=1).reshape(1, -1) - 2*X1@X2.T) / pow(self.sigma_k, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidKernel:\n",
    "    \"\"\"\n",
    "    hyperbolic tangent kernel\n",
    "    :input: X1 (N*D), X2 (M*D)\n",
    "    :output: covariance matrix (N*M)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha \n",
    "    \n",
    "    def __call__(self, X1, X2):\n",
    "        return torch.tanh(self.alpha * X1 @ X2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GP regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP_Regression(nn.Module):\n",
    "    def __init__(self, K, sigma_n, device):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.sigma_n = nn.Parameter(torch.tensor(sigma_n), requires_grad=True)  # noise variance (Hyperparameter)\n",
    "        self.device = device\n",
    "        self.Sigma = torch.diag(torch.ones(7)) * self.sigma_n # output dim (=7)\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_test):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.N = X_train.shape[0]\n",
    "        self.M = X_test.shape[0]\n",
    "        self.D = Y_train.shape[1] # output dim (=7)\n",
    "        self.I = torch.eye(self.N)\n",
    "        # sufficient statistics\n",
    "        self.K_X_X = self.K(self.X_train, self.X_train)\n",
    "        self.K_X_X = torch.block_diag(*[self.K_X_X]*self.D) # coregionalisation matrix (C) is an identity matrix with DxD\n",
    "        self.K_Xt_X = self.K(self.X_test, self.X_train)\n",
    "        self.K_Xt_X = torch.block_diag(*[self.K_Xt_X]*self.D)\n",
    "        self.K_X_Xt = self.K_Xt_X.T\n",
    "        self.K_Xt_Xt = self.K(self.X_test, self.X_test)\n",
    "        self.K_Xt_Xt = torch.block_diag(*[self.K_Xt_Xt]*self.D)\n",
    "        self.vec_Y = self.Y_train.T.reshape(self.D*self.N) # Y concat\n",
    "\n",
    "    def predict(self):\n",
    "        # calculate predictive mean\n",
    "        mean = self.K_Xt_X @ torch.linalg.inv( self.K_X_X + torch.kron(self.Sigma, self.I).to(self.device) ) @ self.vec_Y\n",
    "        return mean.reshape(self.D, -1).T # to compare with Y_test\n",
    "\n",
    "    def __NLL_term_1__(self):\n",
    "        return -0.5*(self.M*self.D) * torch.log(torch.tensor([2*torch.pi]))\n",
    "\n",
    "    def __NLL_term_2__(self, CR): # Omega <- I\n",
    "        Sigma = torch.diag(torch.ones(self.D)) * self.sigma_n\n",
    "        SI = torch.kron(Sigma, self.I).to(self.device) \n",
    "        K = CR + SI\n",
    "        return -0.5 * torch.log(torch.det(K))\n",
    "\n",
    "    def __NLL_term_3__(self, CR): # Omega <- I\n",
    "        Sigma = torch.diag(torch.ones(self.D)) * self.sigma_n\n",
    "        SI = torch.kron(Sigma, self.I).to(self.device)\n",
    "        K = CR + SI\n",
    "        vec_Y = self.Y_train.T.reshape(self.D*self.N)  # Y concat\n",
    "        return -0.5 * vec_Y.T @ torch.linalg.inv(K) @ vec_Y\n",
    "    \n",
    "    def calculate_NLL(self):\n",
    "        K_X_X = self.K(self.X_train, self.X_train)\n",
    "        CR = torch.block_diag(*[K_X_X]*self.D) \n",
    "        return self.__NLL_term_1__().to(self.device) + self.__NLL_term_2__(CR).to(self.device) + self.__NLL_term_3__(CR).to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 611122612352 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\YOUNGBIN\\Documents\\Jupyter Lab\\Advanced-Machine-Learning\\2. Gaussian Process Regression\\model.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000010?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m GP_Regression(K\u001b[39m=\u001b[39mGaussianKernel(sigma_k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), sigma_n\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000010?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000010?line=2'>3</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000010?line=3'>4</a>\u001b[0m mse \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()(pred, Y_test)\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;32mc:\\Users\\YOUNGBIN\\Documents\\Jupyter Lab\\Advanced-Machine-Learning\\2. Gaussian Process Regression\\model.ipynb Cell 11'\u001b[0m in \u001b[0;36mGP_Regression.fit\u001b[1;34m(self, X_train, Y_train, X_test)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000009?line=16'>17</a>\u001b[0m \u001b[39m# sufficient statistics\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000009?line=17'>18</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_X_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000009?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_X_X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mblock_diag(\u001b[39m*\u001b[39;49m[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mK_X_X]\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mD) \u001b[39m# coregionalisation matrix (C) is an identity matrix with DxD\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000009?line=19'>20</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_Xt_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000009?line=20'>21</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_Xt_X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mblock_diag(\u001b[39m*\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_Xt_X]\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AML\\lib\\site-packages\\torch\\functional.py:1104\u001b[0m, in \u001b[0;36mblock_diag\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/functional.py?line=1101'>1102</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m   <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/functional.py?line=1102'>1103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(block_diag, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m-> <a href='file:///c%3A/Users/YOUNGBIN/anaconda3/envs/AML/lib/site-packages/torch/functional.py?line=1103'>1104</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_VariableFunctions\u001b[39m.\u001b[39;49mblock_diag(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 611122612352 bytes."
     ]
    }
   ],
   "source": [
    "model = GP_Regression(K=GaussianKernel(sigma_k=1), sigma_n=0.05, device=device)\n",
    "model.fit(X_train, Y_train, X_test)\n",
    "pred = model.predict()\n",
    "mse = nn.MSELoss()(pred, Y_test).item()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOR approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP_Regression_SOR(nn.Module):\n",
    "    def __init__(self, K, sigma_n, device, B):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.sigma_n = sigma_n  # noise variance (Hyperparameter)\n",
    "        self.device = device\n",
    "        self.Sigma = torch.diag(torch.ones(7)) * self.sigma_n # output dim (=7)\n",
    "        self.B = B # random sample portion (e.g., B=0.1 means 10% of data)\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_test):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.N = X_train.shape[0]\n",
    "        self.M = X_test.shape[0]\n",
    "        self.D = Y_train.shape[1] # output dim (=7)\n",
    "        self.I = torch.eye(self.N)\n",
    "        self.B_train = X_train[torch.randperm(self.N)[:int(self.N*self.B)]]#.to(self.device)\n",
    "        # sufficient statistics\n",
    "        self.K_Xt_B = self.K(self.X_test, self.B_train)\n",
    "        self.K_B_X = self.K(self.B_train, self.X_train)\n",
    "        self.K_X_B = self.K_B_X.T\n",
    "        self.K_B_B = self.K(self.B_train, self.B_train)\n",
    "        self.vec_Y = self.Y_train.T.reshape(self.D*self.N) # Y concat\n",
    "\n",
    "    def predict(self):\n",
    "        # calculate predictive mean\n",
    "        term_1 = torch.block_diag(*[self.K_Xt_B]*self.D)\n",
    "        # term_2 = torch.linalg.inv(\n",
    "        #     torch.block_diag(*[self.K_B_X @ self.K_X_B]*self.D) + torch.kron(self.Sigma, self.K_B_B).to(self.device)\n",
    "        # )\n",
    "        term_2 = torch.linalg.inv(\n",
    "            torch.kron(torch.diag(torch.ones(self.D)), self.K_B_X@self.K_X_B) + torch.kron(self.Sigma, self.K_B_B)\n",
    "        )\n",
    "        term_3 = torch.block_diag(*[self.K_B_X]*self.D) @ self.vec_Y\n",
    "        mean = term_1 @ term_2 @ term_3 \n",
    "        return mean.reshape(self.D, -1).T # to compare with Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360.07234805651103\n"
     ]
    }
   ],
   "source": [
    "model = GP_Regression_SOR(K=GaussianKernel(sigma_k=1), sigma_n=0.05, device=device, B=0.01) # 10%에 10분\n",
    "model.fit(X_train, Y_train, X_test)\n",
    "pred = model.predict()\n",
    "mse = nn.MSELoss()(pred, Y_test).item()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sigma_n': 0.05},\n",
       " {'sigma_n': 0.1},\n",
       " {'sigma_n': 1},\n",
       " {'sigma_n': 5},\n",
       " {'sigma_n': 10}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'sigma_n': [0.05, 0.1, 1, 5, 10]}\n",
    "grid_list = list(ParameterGrid(grid))\n",
    "grid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sigma_n': 0.05}\n",
      "Runtime::  373195\n",
      "MSE loss:  13070863.921733147\n",
      "\n",
      "{'sigma_n': 0.1}\n",
      "Runtime::  673963\n",
      "MSE loss:  11031468.943707984\n",
      "\n",
      "{'sigma_n': 1}\n",
      "Runtime::  310300\n",
      "MSE loss:  60396.19706776355\n",
      "\n",
      "{'sigma_n': 5}\n",
      "Runtime::  553296\n",
      "MSE loss:  288277964.1572634\n",
      "\n",
      "{'sigma_n': 10}\n",
      "Runtime::  895313\n",
      "MSE loss:  186614.25133434022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for case in grid_list:\n",
    "\n",
    "#     model = GP_Regression_SOR(K=LinearKernel(), sigma_n=case['sigma_n'], device=device, B=0.1)\n",
    "#     start_time = datetime.now()\n",
    "#     model.fit(X_train, Y_train, X_valid)\n",
    "#     pred = model.predict()\n",
    "#     runtime = datetime.now() - start_time\n",
    "#     mse = nn.MSELoss()(pred, Y_valid).item()\n",
    "    \n",
    "#     print(case)\n",
    "#     print('Runtime:: ', runtime.microseconds)\n",
    "#     print('MSE loss: ', mse)\n",
    "#     print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sigma_n': 0.05}\n",
      "500430.33435679396\n",
      "\n",
      "{'sigma_n': 0.1}\n",
      "3946152.080139412\n",
      "\n",
      "{'sigma_n': 1}\n",
      "150596273.3726202\n",
      "\n",
      "{'sigma_n': 5}\n",
      "3000047.9525331864\n",
      "\n",
      "{'sigma_n': 10}\n",
      "1882629.2845048755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-validation\n",
    "\n",
    "for case in grid_list:\n",
    "\n",
    "    X, Y = X_train, Y_train\n",
    "    KF = KFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "    mse_list = []\n",
    "    start_time = datetime.now()\n",
    "    for train_idx, valid_idx in KF.split(X):\n",
    "        X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "        X_valid, Y_valid = X[valid_idx], Y[valid_idx]\n",
    "        # model\n",
    "        model = GP_Regression_SOR(K=LinearKernel(), sigma_n=case['sigma_n'], device=device, B=0.1)\n",
    "        model.fit(X_train, Y_train, X_valid)\n",
    "        pred = model.predict()\n",
    "        mse = nn.MSELoss()(pred, Y_valid).item()\n",
    "        gc.collect(); torch.cuda.empty_cache() # clear memory\n",
    "        mse_list.append(mse)\n",
    "    final_loss = np.mean(mse_list)\n",
    "    runtime = datetime.now() - start_time\n",
    "\n",
    "    print(case)\n",
    "    print('Runtime:: ', runtime.microseconds)\n",
    "    print(final_loss)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sigma_k': 0.05, 'sigma_n': 0.05},\n",
       " {'sigma_k': 0.05, 'sigma_n': 0.1},\n",
       " {'sigma_k': 0.05, 'sigma_n': 1},\n",
       " {'sigma_k': 0.05, 'sigma_n': 5},\n",
       " {'sigma_k': 0.05, 'sigma_n': 10},\n",
       " {'sigma_k': 1, 'sigma_n': 0.05},\n",
       " {'sigma_k': 1, 'sigma_n': 0.1},\n",
       " {'sigma_k': 1, 'sigma_n': 1},\n",
       " {'sigma_k': 1, 'sigma_n': 5},\n",
       " {'sigma_k': 1, 'sigma_n': 10},\n",
       " {'sigma_k': 5, 'sigma_n': 0.05},\n",
       " {'sigma_k': 5, 'sigma_n': 0.1},\n",
       " {'sigma_k': 5, 'sigma_n': 1},\n",
       " {'sigma_k': 5, 'sigma_n': 5},\n",
       " {'sigma_k': 5, 'sigma_n': 10}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'sigma_n': [0.05, 0.1, 1, 5, 10],\n",
    "        'sigma_k': [0.05, 1, 5]}\n",
    "grid_list = list(ParameterGrid(grid))\n",
    "grid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\YOUNGBIN\\Documents\\Jupyter Lab\\Advanced-Machine-Learning\\2. Gaussian Process Regression\\model.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000023?line=3'>4</a>\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000023?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, Y_train, X_valid)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000023?line=5'>6</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000023?line=6'>7</a>\u001b[0m runtime \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000023?line=7'>8</a>\u001b[0m mse \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()(pred, Y_valid)\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;32mc:\\Users\\YOUNGBIN\\Documents\\Jupyter Lab\\Advanced-Machine-Learning\\2. Gaussian Process Regression\\model.ipynb Cell 15'\u001b[0m in \u001b[0;36mGP_Regression_SOR.predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=27'>28</a>\u001b[0m term_1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mblock_diag(\u001b[39m*\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_Xt_B]\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=28'>29</a>\u001b[0m \u001b[39m# term_2 = torch.linalg.inv(\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=29'>30</a>\u001b[0m \u001b[39m#     torch.block_diag(*[self.K_B_X @ self.K_X_B]*self.D) + torch.kron(self.Sigma, self.K_B_B).to(self.device)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=30'>31</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=31'>32</a>\u001b[0m term_2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=32'>33</a>\u001b[0m     torch\u001b[39m.\u001b[39mkron(torch\u001b[39m.\u001b[39mdiag(torch\u001b[39m.\u001b[39mones(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mK_B_X\u001b[39m@self\u001b[39;49m\u001b[39m.\u001b[39;49mK_X_B) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mkron(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSigma, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_B_B)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=33'>34</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=34'>35</a>\u001b[0m term_3 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mblock_diag(\u001b[39m*\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_B_X]\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD) \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvec_Y\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000014?line=35'>36</a>\u001b[0m mean \u001b[39m=\u001b[39m term_1 \u001b[39m@\u001b[39m term_2 \u001b[39m@\u001b[39m term_3 \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for case in grid_list:\n",
    "\n",
    "    model = GP_Regression_SOR(K=GaussianKernel(sigma_k=case['sigma_k']), sigma_n=case['sigma_n'], device=device, B=0.1)\n",
    "    start_time = datetime.now()\n",
    "    model.fit(X_train, Y_train, X_valid)\n",
    "    pred = model.predict()\n",
    "    runtime = datetime.now() - start_time\n",
    "    mse = nn.MSELoss()(pred, Y_valid).item()\n",
    "    \n",
    "    print(case)\n",
    "    print('Runtime:: ', runtime.microseconds)\n",
    "    print('MSE loss: ', mse)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sigma_k': 0.05, 'sigma_n': 0.05}\n",
      "Runtime::  337810\n",
      "373.6529561869671\n",
      "\n",
      "{'sigma_k': 0.05, 'sigma_n': 0.1}\n",
      "Runtime::  663101\n",
      "372.86271657262324\n",
      "\n",
      "{'sigma_k': 0.05, 'sigma_n': 1}\n",
      "Runtime::  445649\n",
      "372.2922511038711\n",
      "\n",
      "{'sigma_k': 0.05, 'sigma_n': 5}\n",
      "Runtime::  145060\n",
      "374.9640591895366\n",
      "\n",
      "{'sigma_k': 0.05, 'sigma_n': 10}\n",
      "Runtime::  566051\n",
      "377.20190016192936\n",
      "\n",
      "{'sigma_k': 1, 'sigma_n': 0.05}\n",
      "Runtime::  292263\n",
      "353.11032374130866\n",
      "\n",
      "{'sigma_k': 1, 'sigma_n': 0.1}\n",
      "Runtime::  974394\n",
      "355.90488723847614\n",
      "\n",
      "{'sigma_k': 1, 'sigma_n': 1}\n",
      "Runtime::  998744\n",
      "357.3220117054649\n",
      "\n",
      "{'sigma_k': 1, 'sigma_n': 5}\n",
      "Runtime::  294131\n",
      "363.9838755181798\n",
      "\n",
      "{'sigma_k': 1, 'sigma_n': 10}\n",
      "Runtime::  585363\n",
      "369.5308261040593\n",
      "\n",
      "{'sigma_k': 5, 'sigma_n': 0.05}\n",
      "Runtime::  766372\n",
      "157.61386283562814\n",
      "\n",
      "{'sigma_k': 5, 'sigma_n': 0.1}\n",
      "Runtime::  311069\n",
      "168.8990889584535\n",
      "\n",
      "{'sigma_k': 5, 'sigma_n': 1}\n",
      "Runtime::  520360\n",
      "199.70875205430255\n",
      "\n",
      "{'sigma_k': 5, 'sigma_n': 5}\n",
      "Runtime::  965865\n",
      "248.90015127363637\n",
      "\n",
      "{'sigma_k': 5, 'sigma_n': 10}\n",
      "Runtime::  718645\n",
      "274.3767792602455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-validation\n",
    "\n",
    "for case in grid_list:\n",
    "\n",
    "    X, Y = X_train, Y_train\n",
    "    KF = KFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "    mse_list = []\n",
    "    start_time = datetime.now()\n",
    "    for train_idx, valid_idx in KF.split(X):\n",
    "        X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "        X_valid, Y_valid = X[valid_idx], Y[valid_idx]\n",
    "        # model\n",
    "        model = GP_Regression_SOR(K=GaussianKernel(sigma_k=case['sigma_k']), sigma_n=case['sigma_n'], device=device, B=0.1)\n",
    "        model.fit(X_train, Y_train, X_valid)\n",
    "        pred = model.predict()\n",
    "        mse = nn.MSELoss()(pred, Y_valid).item()\n",
    "        gc.collect(); torch.cuda.empty_cache() # clear memory\n",
    "        mse_list.append(mse)\n",
    "    final_loss = np.mean(mse_list)\n",
    "    runtime = datetime.now() - start_time\n",
    "\n",
    "    print(case)\n",
    "    print('Runtime:: ', runtime.microseconds)\n",
    "    print(final_loss)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.05, 'sigma_n': 0.05},\n",
       " {'alpha': 0.05, 'sigma_n': 0.1},\n",
       " {'alpha': 0.05, 'sigma_n': 1},\n",
       " {'alpha': 0.05, 'sigma_n': 5},\n",
       " {'alpha': 0.05, 'sigma_n': 10},\n",
       " {'alpha': 1, 'sigma_n': 0.05},\n",
       " {'alpha': 1, 'sigma_n': 0.1},\n",
       " {'alpha': 1, 'sigma_n': 1},\n",
       " {'alpha': 1, 'sigma_n': 5},\n",
       " {'alpha': 1, 'sigma_n': 10},\n",
       " {'alpha': 5, 'sigma_n': 0.05},\n",
       " {'alpha': 5, 'sigma_n': 0.1},\n",
       " {'alpha': 5, 'sigma_n': 1},\n",
       " {'alpha': 5, 'sigma_n': 5},\n",
       " {'alpha': 5, 'sigma_n': 10}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'sigma_n': [0.05, 0.1, 1, 5, 10],\n",
    "        'alpha': [0.05, 1, 5]}\n",
    "grid_list = list(ParameterGrid(grid))\n",
    "grid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.05, 'sigma_n': 0.05}\n",
      "Runtime::  861084\n",
      "MSE loss:  8.259437873146231\n",
      "\n",
      "{'alpha': 0.05, 'sigma_n': 0.1}\n",
      "Runtime::  954705\n",
      "MSE loss:  7.292323144034025\n",
      "\n",
      "{'alpha': 0.05, 'sigma_n': 1}\n",
      "Runtime::  227890\n",
      "MSE loss:  7.260592703719794\n",
      "\n",
      "{'alpha': 0.05, 'sigma_n': 5}\n",
      "Runtime::  271570\n",
      "MSE loss:  10.048423248229945\n",
      "\n",
      "{'alpha': 0.05, 'sigma_n': 10}\n",
      "Runtime::  775042\n",
      "MSE loss:  116.71605128861682\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 0.05}\n",
      "Runtime::  964304\n",
      "MSE loss:  26.81745081897477\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 0.1}\n",
      "Runtime::  149503\n",
      "MSE loss:  36.594688592294084\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 1}\n",
      "Runtime::  240528\n",
      "MSE loss:  32.434234757676535\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 5}\n",
      "Runtime::  919076\n",
      "MSE loss:  32.37575823305953\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 10}\n",
      "Runtime::  872059\n",
      "MSE loss:  37.32291690285767\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 0.05}\n",
      "Runtime::  17034\n",
      "MSE loss:  34.774999357897315\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 0.1}\n",
      "Runtime::  819889\n",
      "MSE loss:  32.8562655970894\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 1}\n",
      "Runtime::  965240\n",
      "MSE loss:  41.35945000538567\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 5}\n",
      "Runtime::  19321\n",
      "MSE loss:  41.213961515935445\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 10}\n",
      "Runtime::  168143\n",
      "MSE loss:  34.75558085389525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for case in grid_list:\n",
    "\n",
    "    model = GP_Regression_SOR(K=SigmoidKernel(alpha=case['alpha']), sigma_n=case['sigma_n'], device=device, B=0.1)\n",
    "    start_time = datetime.now()\n",
    "    model.fit(X_train, Y_train, X_valid)\n",
    "    pred = model.predict()\n",
    "    runtime = datetime.now() - start_time\n",
    "    mse = nn.MSELoss()(pred, Y_valid).item()\n",
    "    \n",
    "    print(case)\n",
    "    print('Runtime:: ', runtime.microseconds)\n",
    "    print('MSE loss: ', mse)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.05, 'sigma_n': 0.05}\n",
      "Runtime::  428384\n",
      "347.4473421766501\n",
      "\n",
      "{'alpha': 0.05, 'sigma_n': 0.1}\n",
      "Runtime::  323127\n",
      "425.1552264930798\n",
      "\n",
      "{'alpha': 0.05, 'sigma_n': 1}\n",
      "Runtime::  324164\n",
      "372.8934757857834\n",
      "\n",
      "{'alpha': 0.05, 'sigma_n': 5}\n",
      "Runtime::  315283\n",
      "415.6811903484428\n",
      "\n",
      "{'alpha': 0.05, 'sigma_n': 10}\n",
      "Runtime::  318287\n",
      "763.9305913289479\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 0.05}\n",
      "Runtime::  329295\n",
      "392.9725012705678\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 0.1}\n",
      "Runtime::  328295\n",
      "70142.58243024274\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 1}\n",
      "Runtime::  319287\n",
      "384.1036544636424\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 5}\n",
      "Runtime::  328567\n",
      "349.19790351265203\n",
      "\n",
      "{'alpha': 1, 'sigma_n': 10}\n",
      "Runtime::  320555\n",
      "393.24389765075546\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 0.05}\n",
      "Runtime::  315398\n",
      "349.5109498661801\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 0.1}\n",
      "Runtime::  305277\n",
      "573.7738458207726\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 1}\n",
      "Runtime::  292219\n",
      "521.9446438603425\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 5}\n",
      "Runtime::  297566\n",
      "564.6281247663621\n",
      "\n",
      "{'alpha': 5, 'sigma_n': 10}\n",
      "Runtime::  291098\n",
      "522.1914634517682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-validation\n",
    "\n",
    "for case in grid_list:\n",
    "\n",
    "    X, Y = X_train, Y_train\n",
    "    KF = KFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "    mse_list = []\n",
    "    start_time = datetime.now()\n",
    "    for train_idx, valid_idx in KF.split(X):\n",
    "        X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "        X_valid, Y_valid = X[valid_idx], Y[valid_idx]\n",
    "        # model\n",
    "        model = GP_Regression_SOR(K=SigmoidKernel(alpha=case['alpha']), sigma_n=case['sigma_n'], device=device, B=0.1)\n",
    "        model.fit(X_train, Y_train, X_valid)\n",
    "        pred = model.predict()\n",
    "        mse = nn.MSELoss()(pred, Y_valid).item()\n",
    "        gc.collect(); torch.cuda.empty_cache() # clear memory\n",
    "        mse_list.append(mse)\n",
    "    final_loss = np.mean(mse_list)\n",
    "    runtime = datetime.now() - start_time\n",
    "\n",
    "    print(case)\n",
    "    print('Runtime:: ', runtime.microseconds)\n",
    "    print(final_loss)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Other regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  200181\n",
      "MSE loss:  10.719762261306766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = X_train, Y_train\n",
    "start_time = datetime.now()\n",
    "model = MultiOutputRegressor(Ridge(random_state=2022)).fit(X, y)\n",
    "pred = model.predict(X_test)\n",
    "runtime = datetime.now() - start_time\n",
    "mse = mean_squared_error(pred, Y_test).item()\n",
    "\n",
    "print('Runtime: ', runtime.microseconds)\n",
    "print('MSE loss: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO - NLL optimizer (discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Parameter: 0.05000000074505806\n",
      "\n",
      "[Iteration 0]\n",
      "NLL: 970830.0\n",
      "Paremeter:  18.334877014160156\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 1]\n",
      "NLL: inf\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 2]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 3]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 4]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 5]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 6]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 7]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n",
      "MSE: 376.5684566220583\n",
      "\n",
      "[Iteration 8]\n",
      "NLL: nan\n",
      "Paremeter:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\YOUNGBIN\\Documents\\Jupyter Lab\\Advanced-Machine-Learning\\2. Gaussian Process Regression\\model.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mparameters()))):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mParemeter: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mparameters())[i]\u001b[39m.\u001b[39mitem())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=17'>18</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=18'>19</a>\u001b[0m mse \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()(pred, Y_test)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000069?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMSE:\u001b[39m\u001b[39m\"\u001b[39m, mse)\n",
      "\u001b[1;32mc:\\Users\\YOUNGBIN\\Documents\\Jupyter Lab\\Advanced-Machine-Learning\\2. Gaussian Process Regression\\model.ipynb Cell 9'\u001b[0m in \u001b[0;36mGP_Regression.predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000010?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000010?line=27'>28</a>\u001b[0m     \u001b[39m# calculate predictive mean\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000010?line=28'>29</a>\u001b[0m     mean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_Xt_X \u001b[39m@\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv( \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mK_X_X \u001b[39m+\u001b[39;49m torch\u001b[39m.\u001b[39;49mkron(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSigma, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mI)\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice) ) \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvec_Y\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/YOUNGBIN/Documents/Jupyter%20Lab/Advanced-Machine-Learning/2.%20Gaussian%20Process%20Regression/model.ipynb#ch0000010?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mean\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00002)\n",
    "n_iter=50\n",
    "print(f'Initial Parameter: {list(model.parameters())[0].item()}')\n",
    "print('')\n",
    "for i in range(n_iter):\n",
    "    print(f'[Iteration {i}]')\n",
    "    nll = model.calculate_NLL()\n",
    "    optimizer.zero_grad()\n",
    "    nll.backward() # calculate derivatives\n",
    "    optimizer.step() # update parameters\n",
    "    print(f\"NLL: {nll.item()}\")\n",
    "    for i in range(len(list(model.parameters()))):\n",
    "        print('Paremeter: ', list(model.parameters())[i].item())\n",
    "    pred = model.predict()\n",
    "    mse = nn.MSELoss()(pred, Y_test).item()\n",
    "    print(f\"MSE:\", mse)\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f37873089bc99999a4c22445a6971dc9322bb05dc63dba22dd50e8a2bf7bc1c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('AML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
